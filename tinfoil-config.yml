shim-version: v0.1.9@sha256:410510c9e8e4c7489dd201fede302dee8455075ca28f4f0abbf84bded943b8f1
cvm-version: 0.4.1
cpus: 32
memory: 524288
gpus: full
vllm: false

models:
  - name: "llama3-3-70b-int4"
    repo: "lambdalabs/Llama-3.3-70B-Instruct-AWQ-4bit@a70257cf10f368114a66115c315def76a1227e26"
    mpk: "06002d4871dbd882fc8b4c385e5181fdd85615e514f4efca3b6b3a3a774a36d2_39785426944_58b5d994-b471-58c9-8058-d224be115e1a"
  - name: "llama3-3-70b-fp8"
    repo: "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic@984c96b73bcf6a675945bac6382b9ed551e5d42b"
    mpk: "0d0be05062e4d3fadc17176cffd1ef6b518a02b0410bd897723f423074ec6cb5_72687374336_99f5f660-3ee0-5626-9772-2f082314e763"
  - name: "llama4-scout-fp8"
    repo: "RedHatAI/Llama-4-Scout-17B-16E-Instruct-FP8-dynamic@98c5271e2d23f7f1fe1cc67858dc8428f5b59cf2"
    mpk: "58a7409901493b9f49c003f9013d6a549a1f3c71c9e9bf836e3be90cf38688ed_114675494912_1e8bd52e-1473-5b85-9424-eff5c4780bb9"
  - name: "llama-scout"
    repo: "RedHatAI/Llama-4-Scout-17B-16E-Instruct@f619fb674aa868a9ae713b112601e9269ea908e8"
    mpk: "f7cc2c98f077b22e73836d63eeef74e734114142ba8c480078229791cc2dc461_217315737600_358f7a5a-f506-5300-b735-a133c19a2fb6"
  - name: "llama-maverick-fp8"
    repo: "RedHatAI/Llama-4-Maverick-17B-128E-Instruct-FP8@ad751fe44a9a92326ce966d980e325fbe2c832c3"
    mpk: "0a717ba1d1462abc04d15a22cb903be30df2385de45640fa73edec7115a74567_416789741568_710a7d73-dd03-55ea-b9b3-510bfaec15ba"
  - name: "llama-maevrick"
    repo: "RedHatAI/Llama-4-Maverick-17B-128E-Instruct@ead348b0b31c5a923afa42ef3e35786884395402"
    mpk: "203faad15ba5fbd8b216d93a425320150dee0e04b4d648589c27f620fa018556_803199680512_de9c7343-2085-59d4-b526-022470bae76a"

shim:
  listen-port: 443
  upstream-port: 8087
  tls-challenge: dns
  publish-attestation: false
  paths:
    - /v1/chat/completions
    - /metrics